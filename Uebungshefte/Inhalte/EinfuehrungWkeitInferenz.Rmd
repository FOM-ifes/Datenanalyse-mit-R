# Kapitel `r kap <- kap+1; kap`: Einführung Wahrscheinlichkeit und Inferenz


## Zufall und Wahrscheinlichkeit
In dieser Übung werden wir ein wenig programmieren, daher bietet es sich an, die Befehle in einem Skript zu speichern. Gehen Sie dazu in RStudio in das Menü `File` und dort auf `New File` und wählen `R Script` aus. Dies können Sie dann am Ende über `File` und `Save` bzw. `Save As` speichern -- und über `Open File` später auch wieder öffnen. Um die Befehle an die Konsole zu übergeben klicken Sie entweder auf `Run` (nur ausgewählte Zeile, Tastenkürzel `Strg+Enter`) oder `Source` (ganzes Programm).

Zunächst laden wir wieder das Zusatzpaket mosaic, falls noch nicht geschehen:
```{r eval=FALSE, message=FALSE}
library(mosaic)
```

Um den Zufall zu bändigen, setzen wir den Zufallszahlengenerator, z.B. auf `1896`

```{r}
set.seed(1896)
```
Dieser Befehl sorgt dafür, dass wir immer denselben "Zufall" haben.

Beim Roulette gibt es 37 Zahlen und 3 Farben: 0-36, wobei 18 Zahlen Schwarz, 18 Zahlen Rot und die 0 Grün ist -- auf die Farbe Grün können Sie auch nicht setzen.

Angenommen Sie setzen auf Farbe. Dann beträgt Ihre Gewinnwahrscheinlichkeit $\frac{18}{37}$, da 18 von 37 Fächern "ihre" Farbe hat, die Wahrscheinlichkeit eines Verlustes liegt bei $\frac{19}{37}=1-\frac{18}{37}$. 

Definieren wir in R einen `factor`-Vektor mit zwei Elementen für Gewinn und Verlust:
```{r}
roulette <- factor(c("Gewinn", "Verlust"))
```
Mit diesem Vektor können wir jetzt virtuell und ganz ohne Risiko über den Befehl `resample` Roulette spielen

```{r}
resample(roulette, 
         size = 1, 
         prob = c(18/37, 19/37))
resample(roulette, 
         size = 10, 
         prob = c(18/37, 19/37))
```
Mit dem Argument `size` wird also eingestellt, wie oft Roulette gespielt wird, `prob` ist der Vektor der Wahrscheinlichkeiten für die einzelnen Elemente im Ereignisvektor, hier `roulette`. `resample` heißt Ziehen mit Zurücklegen.

Über
```{r}
spiele <- resample(roulette, 
                   size = 100, 
                   prob = c(18/37, 19/37))
```
wird dem Vektor `spiele` das Ergebnis von `100` Roulettespielen zugewiesen. Die Häufigkeitsverteilung erhalten wir wie gewohnt über den Befehl `tally`:
```{r}
tally(~spiele, format = "proportion")
```

Das **Gesetz der großen Zahl** sagt aus, dass sich auf *lange* Sicht die beobachtete relative Häufigkeit der theoretischen Wahrscheinlichkeit annähert:
```{r}
tally(~resample(roulette, 
                size = 10, 
                prob = c(18/37, 19/37)), 
       format="proportion")
tally(~resample(roulette, 
                size = 100, 
                prob = c(18/37, 19/37)), 
       format="proportion")
tally(~resample(roulette, 
                size = 1000, 
                prob = c(18/37, 19/37)), 
       format="proportion")
tally(~resample(roulette, 
                size = 1000000, 
                prob = c(18/37, 19/37)), 
       format="proportion")
```

Die theoretische Wahrscheinlichkeit eines Gewinns liegt bei $\frac{18}{37} \approx `r round(18/37, 4)`$: Achtung, das Gesetz der großen Zahl gilt für den Durchschnitt und auf lange Sicht, evtl. Ungleichgewichte, z.B. 5 Gewinne in Folge, werden im Laufe der Zeit abgeschwächt und nicht durch anschließende 5 Verluste ausgeglichen.

Bei bestimmten Spielstrategien, z.B. bei der sogenannten Martingale oder Verdoppelungsstrategie, ist man daran interessiert wie wahrscheinlich es ist z.B. 8-mal in Folge zu verlieren. Natürlich kann das mit Hilfe der *Binomialverteilung* ausgerechnet werden, wir können es aber auch simulieren: `do()` ist eine einfache Schleifenfunktion in mosaic. Um z.B. 10000-mal jeweils 8 Runden Roulette zu spielen -- und das Ergebnis zu speichern -- genügt:


```{r}
farbspiele <- do(10000)*
                tally(~resample(roulette, 
                                size = 8, 
                                prob = c(18/37, 19/37)), 
                       format="proportion")
```
`farbspiele` ist jetzt ein Datensatz (`data.frame`) mit 10000 Zeilen (=Simulationen) und den relativen Häufigkeiten für Gewinn und Verlust in den 8 Spielen in den Spalten.

Das Balkendiagramm der relativen Verlusthäufigkeit zeigt, dass es zwar selten aber doch vorkommt, alle 8 Spiele zu verlieren.
```{r}
gf_bar(~Verlust, data=farbspiele)
```

Wir haben in `r sum(farbspiele$Verlust==1)` von 10000 Wiederholungen nur verloren, d.h. 8 von 8 Spielen.


***
**Übung:** 

1.  Wenn Sie statt auf Farbe auf eine Zahl setzen, beträgt Ihre Gewinnwahrscheinlichkeit $\frac{1}{37}$. Simulieren Sie 10000-mal 10 Spiele. Wie oft haben Sie mindestens 1-mal gewonnen?

***

Wenn wir uns die Verteilung der Daten der Übung anschauen
```{r}
zahlspiele <- do(10000)*
                tally(~resample(roulette, 
                                size = 10, 
                                prob = c(1/37, 36/37)), 
                       format = "proportion")

gf_bar(~Gewinn, data=zahlspiele)
```

stellen wir fest, dass diese Daten (leider) extrem rechtsschief sind, d.h., i.d.R. gewinnen wir in keiner der 10 Runden, Gewinn=0. Wenn wir  `size=10` durch `size=1000` ersetzen (d.h., bei jeden der 10000 Simulationen 1000 Runden spielen), passiert folgendes (Darstellung jetzt als Histogramm, da es zu sehr viele mögliche Ausprägungen für die Anzahl Gewinne gibt):

```{r}
zahlspiele2 <- do(10000)*
                 tally(~resample(roulette, 
                                 size = 1000, 
                                 prob = c(1/37, 36/37)), 
                        format = "proportion")

gf_histogram(~Gewinn, data=zahlspiele2)
```

Die Daten werden *normaler*, symmetrischer, d.h., die Verteilung des Gewinnanteilswertes nähert sich einer Normalverteilung an. Dieses Phänomen ist der Hintergrund des **Zentralen Grenzwertsatzes**.

***
**Übung:** 

2.  Zurück zum Farbspiel (`farbspiele`): Wie hoch schätzen Sie die Wahrscheinlichkeit anhand der Simulation, dass Sie mindestens die Hälfte Ihrer 8 Spiele gewinnen? 

***
Richtig: `r mean(farbspiele$Gewinn>=0.5)`, das ist also anscheinend recht wahrscheinlich, während der relative Anteil der Spiele, in denen Sie maximal 1 der 8 Spiele gewinnen, recht klein ist:
```{r, eval = TRUE}
anteil <- prop(farbspiele$Gewinn <= 1/8)
anteil
```
Das kommt also eher selten vor. Pech. Vielleicht würden Ihnen aber auch Zweifel kommen, ob der Tisch fair ist. In der Simulation liegt also die Wahrscheinlichkeit, bei einem fairen Tisch bei 8 Spielen höchstens einmal zu gewinnen bei `r mean(farbspiele$Gewinn <= 1/8)*100`$\,$ \%. 

## Hypothesentest, p-Wert und Konfidenzintervall
Im Paper 
*Hose, C., Lübke, K., Nolte, T., und Obermeier, T. (2012): Ratingprozess und Ratingergebnis: Ein Experiment bei qualitativen Ratingkriterien, Kredit & Rating Praxis (6), 12-14* 
wird folgendes Experiment untersucht: Unterscheidet sich die Einschätzung (Rating) eines Unternehmens, je nach dem, ob die Person alleiniger Entscheider (Typ A) oder derjenige ist, der die  Entscheidungsvorlage vorbereitet (Typ B). Im Rahmen des Experiments wurden die Studierenden zufällig den verschiedenen Typen A und B zugeordnet. Von 151 alleinigen Entscheidern (Typ A) beurteilten 79 das Beispielunternehmen überwiegend positiv (++, +), von 143 Entscheidungsvorlagenerstellern (Typ B) entschieden ebenfalls 79 überwiegend positiv. 

Zeigt das unterschiedliche Verhältnis: Typ A: $\frac{79}{151}=`r round(79/151*100,2)`$$\,$ zu Typ B: $\frac{79}{143}=`r round(79/143*100,2)`$$\,$, dass alleinige Entscheider die Bonität kritischer einstufen, oder könnte das Ergebnis Zufall sein?

Das Chancenverhältnis, das **Odds Ratio** liegt bei $\frac{\frac{79}{151-79}}{\frac{79}{143-79}}=`r round((79/(151-79))/(79/(143-79)), 2)`$, dass ein alleiniger Entscheider positiv einstuft -- im Vergleich zum vorläufigen Entscheider.

Zunächst erzeugen wir einen Vektor mit zwei Ausprägungen mit den Entscheidungstypen, aus dem wir simulieren können:

```{r}
typ <- factor(c("A", "B"))
entscheider <- rep(typ, c(151, 143))

tally(~entscheider)
```

sowie einen Vektor der Entscheidungen:

```{r}
rating <- factor(c("Positiv", "Nicht Positiv"))
entscheidungen <- rep(rating, c(79 + 79, (151 + 143) - (79 + 79)))

tally(~entscheidungen)
                      
```

Aus diesem Vektor ziehen wir eine zufällige Stichprobe von 151 Entscheidungen von Typ A.
```{r}
simentscheidung <- sample(entscheidungen, size = 151)

tally(~simentscheidung)
```
Hier wären also zufällig `r tally(~simentscheidung)["Positiv"]` der 151 Entscheidungen des Typ A positiv gewesen -- wenn es keinen Zusammanhang zwischen Entscheidungstyp und Ratingentscheidung gibt. `sample` bedeutet Ziehen ohne Zurücklegen, d.h., jeder der Entscheidungen kann nur einmal gezogen werden.

Wir oft kommt also zufällig heraus, dass höchstens 79 der 151 Entscheidungen des Typs A (alleinige Entscheider) positiv zugeordnet werden? Simulieren wir das z.B. 10000-mal:
```{r}
entsim <- do(10000)*
            tally(~sample(entscheidungen, size = 151))

prop(entsim$Positiv <= 79)
```

Unter der **Nullhyothese**, dass das Ergebnis zufällig war (d.h. es gibt keinen Zusammenhang zwischen Typ und Rating), wurden in der Simulation in `r round(mean(entsim$Positiv<=79)*100,2)`$\,$ \% der Fälle höchstens 79 positive Entscheidungen dem Typ A zufällig zugeordnet. Dieser **p-Wert** spricht also nicht wirklich gegen das Zufallsmodell.
*Hinweis:* Wir werden in späteren Kapiteln bessere Methoden kennenlernen, insbesondere auch solche, die alle Informationen aus den Daten enthalten und sich nicht nur auf einen Anteilswert beziehen.


Über
```{r}
typA <- rep(rating, c(79, 151 - 79))
```
erzeugen wir uns einen Vektor, der die $79$ positiven und $151-79$ nicht positiven Urteile von Typ A (alleinige Entscheidung) enthält.
```{r}
tally(~ typA)
```
Wenn wir jetzt diesen Vektor z.B. 10000-mal resampeln:
```{r}
typAboot <- do(10000)*
              tally(~resample(typA), format = "proportion")
```
erhalten wir 10000 (resampelte) Stichproben, die jeweils einen zufälligen Stichprobenanteil haben:
```{r}
# 79/151: Anteil der Originalstichprobe
gf_histogram(~Positiv, data = typAboot) %>% 
    gf_vline(xintercept = 79/151) 
```

In 95$\,$% der Fälle liegt dieser zufällige Stichprobenanteil hier zwischen 
```{r}
ki <- quantile(~Positiv, 
                data = typAboot, 
                probs = c(0.025, 0.975))
ki

gf_histogram(~Positiv, data = typAboot) %>% 
    gf_vline(xintercept = ki)
```

Dies ist das **nicht-parametrische Bootstrap-Konfidenzintervall**.


***
**Übung:** 

3.  Bestimmen Sie das 90$\,$% nicht-parametrische Bootstrap-Konfidenzintervall für eine nicht-positive Einschätzung im Fall Entscheidungsvorlage (Typ B). Würde damit eine Nullyhpothese $\pi=0.5$ zum Signifikanzniveau 10$\,$% vermutlich verworfen werden?

***




## Rechnen mit der Normalverteilung

### Random Walk
Beim Glücksspiel ist es offensichtlich, aber auch an vielen, vielen anderen Stellen im Leben begegnen wir dem *Zufall*. Daten, Beobachtungen sind häufig Realisationen von sogenannten Zufallsvariablen. Das sind Variablen, deren Werte vom Zufall (und damit auch seinen Modellen und Gesetzen) abhängen. So werden Aktienkurse und -renditen häufig als Random Walk aufgefasst und modelliert - häufig unter der *Annahme* einer Normalverteilung.^[Sowohl die Annahme einer Normalverteilung, als auch die Annahme, dass die Renditen unabhängig voneinander sind (d.h., dass keine *Autokorrelation* vorliegt) und einer identischen Verteilung folgen (hier gleiche Varianz) sind in der Praxis kritisch zu hinterfragen.]


Hier drei Kennzahlen der logarithmierten Tagesrenditen von Aktienunternehmen in 2015 in Prozent.

Anlage | AAPL | FB | GOOGL |
-------|------|----|-------|
Mittelwert|-0.08|0.11|0.15|
Standardabweichung|1.69|1.62|1.77|

Unter der Annahme der unabhängig, identischen Normalverteilung der logarithmierten Renditen können wir jetzt die Wahrscheinlichkeit eines Tagesverlustes der Apple Aktie (AAPL) berechnen über
```{r}
xpnorm(0, mean = -0.08, 
          sd = 1.69 )
```

Die mosaic Funktion `xpnorm` ist eine Erweiterung der normalen R Funktion `pnorm`, die den Wert der Verteilungsfunktion an einer gegebenen Stelle zurückgibt -- für jede Verteilung wird hierfür der vorgestellte Buchstabe `p` verwendet. 

Für Facebook (FB) lag die Wahrscheinlichkeit eines Gewinns demnach bei
```{r}
xpnorm(0, mean = 0.11, 
          sd = 1.62, 
          lower.tail = FALSE)
```

Die Voreinstellung ist `lower.tail = TRUE`, d.h., es wird die Unterschreitungswahrscheinlichkeit angezeigt. Da wir hier aber an der Überschreitungswahrscheinlichkeit (Gewinn) interessiert sind, muss die Option auf `FALSE` gesetzt werden.

***
**Übung:** 

4.  Welche der drei Aktien hat die höchste Wahrscheinlichkeit eine Tagesrendite über 2.5$\,$% zu erzielen?

***


Dabei wird hier immer auch die Z-Transformation, die Standardisierung, mit angegeben.
Am 26.05.2015 ($r=-2.23$) betrug der $z$-Wert der Apple Aktie demnach bei
```{r}
(-2.23 - (-0.08)) / 1.69
```
Die Tagesrendite von Apple war also `r abs((-2.23 - (-0.08)) / 1.69)` Standardabweichungen *unter* dem Mittelwert. 
Für Facebook lag die Tagesrendite bei -1.51, der $z$-Wert demnach bei:
```{r}
(-1.51 - (0.11)) / 1.62
```
Der 26. Mai 2015 war also auch für Facebook-Anlegerinnen kein guter Tag, aber immer noch besser als bei Apple.

***
**Übung:** 

5.  Die Rendite von Google am 26.05.2015 betrug -1.33. Wie hoch ist der $z$-Wert? Interpretieren Sie die Aussage des Ergebnisses.

***

Wenn wir zu einen gegebenen Wert der Rendite den Wert der Verteilungsfunktion, d.h. den prozentualen Anteil kleiner oder gleich großer Werte suchen ($P(X \leq x)$) verwenden wir `pnorm` bzw. `xpnorm`. Wenn die Überschreitungswahrscheinlichkeit ($P(X>x)$) gesucht ist, kann zusätzlich die Option `lower.tail = FALSE` gesetzt werden, oder `1-pnorm()` gerechnet werden.

Um zu einem gegebenen Anteil (Prozentwert) den zugehörigen Wert der Rendite zu finden, wir also das Quantil suchen, dann wird `p` durch `q` ersetzt, also `qnorm` bzw. `xqnorm`.

Z.B. für die 5$\,$% schlechtesten Tage der Apple Aktie
```{r}
xqnorm(0.05, mean = -0.08, 
             sd = 1.69 )
```
Die Wahrscheinlichkeit beträgt also $0,05=5\%$, dass die Tagesrendite unter `r round(qnorm(0.05, mean=-0.08, sd=1.69),2)` liegt.

Für die Facebook Aktie gilt, dass Sie nur mit einer Wahrscheinlichkeit von $0,01=1\%$ über `r xqnorm(0.01, mean=0.11, sd=1.62, lower.tail = FALSE)` lag:
```{r, eval=FALSE}
xqnorm(0.01, mean = 0.11, 
             sd = 1.62, 
             lower.tail = FALSE)
```

***
**Übung:** 

6.  Sie wollen Ihre Google-Aktien absichern. Wie groß ist bei einer maximalen Eintretenswahrscheinlichkeit von $1\%$ der Tagesverlust mindestens?

***

## Übung: Achtsamkeit 
In einem Test zur Achtsamkeit *Sauer S, Lemke J, Wittmann M, Kohls N, Mochty U, and Walach H. (2012) How long is now for mindfulness meditators? Personality and Individual Differences 52(6), 750–754* konnten 34 von 38 Studienteilnehmende der Kontrollgruppe nach einer Instruktion die Dauer der Fixierung des Necker Würfels steigern:  
```{r echo=FALSE, out.width = "20%", fig.align="center", cache=FALSE}
knitr::include_graphics("Inhalte/images/EinfuehrungWkeitInferenz/Necker-Cube-crop.png")
```
[https://www.sciencedirect.com/science/article/pii/S0191886911005939?via%3Dihub](https://www.sciencedirect.com/science/article/pii/S0191886911005939?via%3Dihub).

1.  Kann diese Verbesserung bei fast $90\%$ der Personen zufällig sein? Bestimmen Sie mit Hilfe einer Simulation die Wahrscheinlichkeit, dass zufällig mindestens 34 von 38 Personen eine Verbesserung erzielen.
2.  Bestimmen Sie ein nicht-parametrisches Bootstrap-Konfidenzintervall, dass den Anteilswert der Verbesserung in $95\%$ der Fälle überdeckt.    

## Übung: Intelligenzquotient

Der IQ hat nach Konstruktion einen arithmetischen Mittelwert von 100 bei einer Standardabweichung von 15.

1.  Wie hoch ist der Anteil der Personen mit einem IQ von 130 oder größer?
2.  Welchen IQ sollte eine Person mindestens haben, wenn Sie zu den 1$\,$ \% Personen mit dem höchsten IQ gehören will?



## Literatur


- David M. Diez, Christopher D. Barr, Mine &Ccedil;etinkaya-Rundel (2014): *Introductory Statistics with Randomization and Simulation*, [https://www.openintro.org/stat/textbook.php?stat_book=isrs](https://www.openintro.org/stat/textbook.php?stat_book=isrs),  Kapitel 2
- Nicholas J. Horton, Randall Pruim, Daniel T. Kaplan (2015): Project MOSAIC Little Books *A Student's Guide to R*,  [https://github.com/ProjectMOSAIC/LittleBooks/raw/master/StudentGuide/MOSAIC-StudentGuide.pdf](https://github.com/ProjectMOSAIC/LittleBooks/raw/master/StudentGuide/MOSAIC-StudentGuide.pdf), Kapitel 3.5, 3.6
- Chester Ismay, Albert Y. Kim (2017): ModernDive -- An Introduction to Statistical and Data Sciences via R, [https://ismayc.github.io/moderndiver-book/](https://ismayc.github.io/moderndiver-book/)
- Maike Luhmann (2015): *R für Einsteiger*, Kapitel 12
- Andreas Quatember (2010): *Statistik ohne Angst vor Formeln*, Kapitel 2, 3.1-3.3, 3.13
- Daniel Wollschläger (2014): *Grundlagen der Datenanalyse mit R*, Kapitel 5, 11


### Lizenz
Diese Übung wurde von Karsten Lübke entwickelt und orientiert sich an der Übung zum Buch [OpenIntro](https://www.openintro.org/stat/index.php?stat_book=isrs) von Andrew Bray, Mine &Ccedil;etinkaya-Rundel und Mark Hansen und steht wie diese unter der Lizenz [Creative Commons Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0). 
Kleinere Ergänzungen stammen von Norman Markgraf


### Versionshinweise:
* Datum erstellt: `r Sys.Date()`
* R Version: `r getRversion()`
* `mosaic` Version: `r packageVersion("mosaic")`
